# app.py
import streamlit as st
import numpy as np
import cv2
from skimage.feature import hog
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score
import joblib
from PIL import Image
import io
import os

st.set_page_config(page_title="Digit Recognizer", layout="wide")

# ---------------- Config ----------------
DIGIT_WIDTH = 10
DIGIT_HEIGHT = 20
IMG_WIDTH = 28
IMG_HEIGHT = 28
CLASS_N = 10

# ---------------- Helpers ----------------
def imresize(img, size):
    """Replace for old imresize: expects grayscale (H,W) or color (H,W,3)."""
    h, w = img.shape[:2]
    new_w, new_h = size
    # cv2.resize uses (width, height)
    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return resized

def split2d(img, cell_size, flatten=True):
    h, w = img.shape[:2]
    sx, sy = cell_size
    cells = [np.hsplit(row, w // sx) for row in np.vsplit(img, h // sy)]
    cells = np.array(cells)
    if flatten:
        cells = cells.reshape(-1, sy, sx)
    return cells

def pixels_to_hog_20(img_array):
    hog_featuresData = []
    for img in img_array:
        fd = hog(img,
                 orientations=10,
                 pixels_per_cell=(5, 5),
                 cells_per_block=(1, 1),
                 feature_vector=True)
        hog_featuresData.append(fd)
    hog_features = np.array(hog_featuresData, 'float64')
    return np.float32(hog_features)

def get_contour_precedence(contour, cols):
    return contour[1] * cols + contour[0]

def get_digits(contours, hierarchy):
    # expects contours and hierarchy from findContours
    if hierarchy is None:
        return []
    hierarchy = hierarchy[0]
    bounding_rectangles = [cv2.boundingRect(ctr) for ctr in contours]
    final_bounding_rectangles = []
    # find the most common heirarchy level
    u, indices = np.unique(hierarchy[:, -1], return_inverse=True)
    most_common_heirarchy = u[np.argmax(np.bincount(indices))]

    for r, hr in zip(bounding_rectangles, hierarchy):
        x, y, w, h = r
        if ((w * h) > 250) and (10 <= w <= 200) and (10 <= h <= 200) and hr[3] == most_common_heirarchy:
            final_bounding_rectangles.append(r)
    return final_bounding_rectangles

def load_digits_custom(img_file):
    """Extract digits from a custom training image that contains many digits arranged
    in rows of 10 (similar to the original script). Returns (images, labels)."""
    im = cv2.imread(img_file)
    if im is None:
        raise FileNotFoundError(f"Can't read {img_file}")
    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
    kernel = np.ones((5, 5), np.uint8)
    ret, thresh = cv2.threshold(imgray, 127, 255, 0)
    thresh = cv2.erode(thresh, kernel, iterations=1)
    thresh = cv2.dilate(thresh, kernel, iterations=1)
    thresh = cv2.erode(thresh, kernel, iterations=1)

    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    digits_rectangles = get_digits(contours, hierarchy)
    # sort rectangles row-wise left-to-right
    digits_rectangles.sort(key=lambda x: get_contour_precedence(x, im.shape[1]))

    train_data = []
    train_target = []
    start_class = 1
    for index, rect in enumerate(digits_rectangles):
        x, y, w, h = rect
        im_digit = imgray[y:y + h, x:x + w]
        im_digit = (255 - im_digit)
        im_digit = imresize(im_digit, (IMG_WIDTH, IMG_HEIGHT))
        train_data.append(im_digit)
        train_target.append(start_class % 10)
        if index > 0 and (index + 1) % 10 == 0:
            start_class += 1
    return np.array(train_data), np.array(train_target)

def process_user_image_and_predict(img_bytes, model_pipeline):
    """Given image bytes and a trained pipeline, detect digits and predict.
       Returns annotated_image (RGB), blank_digits_image (RGB), list of (digit_img, pred)."""
    file_bytes = np.asarray(bytearray(img_bytes.read()), dtype=np.uint8)
    im = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    if im is None:
        raise ValueError("Could not decode image")
    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
    blank_image = np.ones_like(im) * 255

    kernel = np.ones((5, 5), np.uint8)
    ret, thresh = cv2.threshold(imgray, 127, 255, 0)
    thresh = cv2.erode(thresh, kernel, iterations=1)
    thresh = cv2.dilate(thresh, kernel, iterations=1)
    thresh = cv2.erode(thresh, kernel, iterations=1)

    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    digits_rectangles = get_digits(contours, hierarchy)

    predictions = []
    for rect in digits_rectangles:
        x, y, w, h = rect
        cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)
        im_digit = imgray[y:y + h, x:x + w]
        im_digit = (255 - im_digit)
        im_digit = imresize(im_digit, (IMG_WIDTH, IMG_HEIGHT))
        hog_feat = pixels_to_hog_20([im_digit])
        pred = model_pipeline.predict(hog_feat)
        label = int(pred[0])
        cv2.putText(im, str(label), (x, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 3)
        cv2.putText(blank_image, str(label), (x, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0), 5)
        predictions.append((im_digit, label))
    # convert BGR->RGB for display
    im_rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    blank_rgb = cv2.cvtColor(blank_image, cv2.COLOR_BGR2RGB)
    return im_rgb, blank_rgb, predictions

# ---------------- Streamlit UI ----------------
st.title("ğŸ“Ÿ ØªØ´Ø®ÛŒØµ Ø§Ø±Ù‚Ø§Ù… Ø¯Ø³Øªâ€ŒÙ†ÙˆÛŒØ³ â€” Streamlit UI")
st.write("Ø¨Ø§ Ø§ÛŒÙ† Ø±Ø§Ø¨Ø· Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø¯ÛŒØªØ§Ø³Øª Ø¯Ø³Øªâ€ŒÙ†ÙˆÛŒØ³ Ø³ÙØ§Ø±Ø´ÛŒ Ø±Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒØŒ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø¯ÛŒ ÛŒØ§ ÛŒÚ© Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø±Ùˆ Ø¨Ø§Ø±Ú¯Ø²Ø§Ø±ÛŒ Ùˆ Ø±ÙˆÛŒ ØªØµÙˆÛŒØ± ØªØ³Øª Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒ.")

# Sidebar controls
st.sidebar.header("Ø¹Ù…Ù„ÛŒØ§Øª")
mode = st.sidebar.radio("Ø§Ù†ØªØ®Ø§Ø¨ Ø­Ø§Ù„Øª:", ("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„", "Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¢Ù…Ø§Ø¯Ù‡ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ"))

# common file uploader for training image
if mode == "Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„":
    st.sidebar.subheader("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¢Ù…ÙˆØ²Ø´")
    uploaded_train = st.sidebar.file_uploader("ØªØµÙˆÛŒØ± Ø¢Ù…ÙˆØ²Ø´ (Ù…Ø«Ù„Ø§Ù‹ custom_train_digits.jpg)", type=['jpg', 'jpeg', 'png'])
    test_size = st.sidebar.slider("Ù†Ø³Ø¨Øª ØªØ³Øª (test_size)", 0.1, 0.5, 0.33, step=0.01)
    pca_n = st.sidebar.slider("ØªØ¹Ø¯Ø§Ø¯ Ù…ÙˆÙ„ÙÙ‡â€ŒÙ‡Ø§ÛŒ PCA", 10, 100, 40, step=1)
    knn_k = st.sidebar.number_input("k Ø¨Ø±Ø§ÛŒ KNN", min_value=1, max_value=15, value=5, step=1)
    svm_C = st.sidebar.number_input("C Ø¨Ø±Ø§ÛŒ SVM", min_value=0.01, value=10.0, step=0.01, format="%.2f")
    svm_gamma = st.sidebar.number_input("gamma Ø¨Ø±Ø§ÛŒ SVM", min_value=0.0001, value=0.001, step=0.0001, format="%.4f")
    train_button = st.sidebar.button("Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´")

    if train_button:
        if uploaded_train is None:
            st.sidebar.error("Ø§Ø¨ØªØ¯Ø§ ØªØµÙˆÛŒØ± Ø¢Ù…ÙˆØ²Ø´ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.")
        else:
            with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø±Ù‚Ø§Ù… Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„..."):
                # save uploaded file to temp path
                train_bytes = uploaded_train.read()
                tmp_path = "tmp_custom_train.jpg"
                with open(tmp_path, "wb") as f:
                    f.write(train_bytes)
                try:
                    digits, labels = load_digits_custom(tmp_path)
                except Exception as e:
                    st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø±Ù‚Ø§Ù… Ø§Ø² ØªØµÙˆÛŒØ± Ø¢Ù…ÙˆØ²Ø´: {e}")
                    st.stop()

                st.write("Ø´Ú©Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:", digits.shape, labels.shape)
                digits, labels = shuffle(digits, labels, random_state=256)
                train_digits_data = pixels_to_hog_20(digits)
                X_train, X_test, y_train, y_test = train_test_split(train_digits_data, labels, test_size=test_size, random_state=42)

                # build pipeline
                knn = KNeighborsClassifier(n_neighbors=int(knn_k))
                svm = SVC(kernel="rbf", C=float(svm_C), gamma=float(svm_gamma), probability=True)
                voting_model = VotingClassifier(estimators=[("knn", knn), ("svm", svm)], voting="soft")
                model_pipeline = Pipeline([
                    ("scaler", StandardScaler()),
                    ("pca", PCA(n_components=int(pca_n))),
                    ("voter", voting_model)
                ])
                model_pipeline.fit(X_train, y_train)
                preds = model_pipeline.predict(X_test)
                acc = accuracy_score(y_test, preds)
                st.success(f"Ø¢Ù…ÙˆØ²Ø´ ØªÙ…Ø§Ù… Ø´Ø¯ â€” Ø¯Ù‚Øª Ø±ÙˆÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡Ù” ØªØ³Øª: {acc:.4f}")
                # save model
                save_name = st.text_input("Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ (.pkl)", value="combo_knn_svm_custom_digits.pkl")
                if st.button("Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„"):
                    joblib.dump(model_pipeline, save_name)
                    st.success(f"Ù…Ø¯Ù„ Ø¯Ø± `{save_name}` Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
                # show a few extracted digits
                st.write("Ù†Ù…ÙˆÙ†Ù‡Ù” Ú†Ù†Ø¯ Ø±Ù‚Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡:")
                cols = st.columns(6)
                for i in range(min(6, len(digits))):
                    with cols[i]:
                        d = digits[i]
                        st.image(d, width=64, caption=str(labels[i]))
                # keep model in session state for immediate use
                st.session_state['model_pipeline'] = model_pipeline

elif mode == "Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¢Ù…Ø§Ø¯Ù‡ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ":
    st.sidebar.subheader("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„")
    uploaded_model = st.sidebar.file_uploader("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ (.pkl)", type=['pkl', 'joblib'])
    load_model_btn = st.sidebar.button("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„")
    if load_model_btn:
        if uploaded_model is None:
            st.sidebar.error("Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.")
        else:
            # save to disk and load
            bytes_data = uploaded_model.read()
            tmp_model = "tmp_loaded_model.pkl"
            with open(tmp_model, "wb") as f:
                f.write(bytes_data)
            try:
                model_pipeline = joblib.load(tmp_model)
                st.success("Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
                st.session_state['model_pipeline'] = model_pipeline
            except Exception as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {e}")

# Prediction panel (common)
st.header("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ ØªØµÙˆÛŒØ± Ú©Ø§Ø±Ø¨Ø±ÛŒ")
uploaded_img = st.file_uploader("ØªØµÙˆÛŒØ± ØªØ³Øª Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ø±Ù‚Ø§Ù… (img_hand.jpg ÛŒØ§ Ù‡Ø± Ø¹Ú©Ø³ Ø¯ÛŒÚ¯Ø±ÛŒ)", type=['jpg', 'jpeg', 'png'])
run_pred = st.button("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ")

if run_pred:
    if 'model_pipeline' not in st.session_state:
        st.error("Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ ÛŒØ§ Ø¢Ù…Ø§Ø¯Ù‡ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯ (Ø§Ø² Ø³Ø§ÛŒØ¯Ø¨Ø§Ø±).")
    else:
        if uploaded_img is None:
            st.error("ØªØµÙˆÛŒØ± ØªØ³Øª Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")
        else:
            try:
                model_pipeline = st.session_state['model_pipeline']
                im_rgb, blank_rgb, predictions = process_user_image_and_predict(uploaded_img, model_pipeline)
                st.subheader("ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©Ø§Ø¯Ø± Ùˆ Ø¨Ø±Ú†Ø³Ø¨ Ø¹Ø¯Ø¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡")
                st.image(im_rgb, use_container_width=True)
                st.subheader("ØªØµÙˆÛŒØ± Ø³ÙÛŒØ¯ ÙÙ‚Ø· Ø¨Ø§ Ø§Ø±Ù‚Ø§Ù… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡")
                st.image(blank_rgb, use_container_width=True)

                if len(predictions) == 0:
                    st.info("Ù‡ÛŒÚ† Ø±Ù‚Ù… Ù‚Ø§Ø¨Ù„ ØªØ´Ø®ÛŒØµÛŒ Ø¯Ø± ØªØµÙˆÛŒØ± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
                else:
                    st.write("ØªØ¹Ø¯Ø§Ø¯ Ø§Ø±Ù‚Ø§Ù… Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡:", len(predictions))
                    # show each extracted digit and prediction
                    cols = st.columns(6)
                    for i, (digit_img, label) in enumerate(predictions[:18]):
                        with cols[i % 6]:
                            st.image(digit_img, width=64, caption=f"pred: {label}")
            except Exception as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±: {e}")

# Footer: quick tips
st.markdown("---")
st.markdown("""
**Ù†Ú©Ø§Øª:**  
- Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ø§Ø² ÛŒÚ© ØªØµÙˆÛŒØ± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø´Ø§Ø¨Ù‡ `custom_train_digits.jpg` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†: Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ø§Ø² 10 Ø±Ù‚Ù… Ù¾Ø´Øª Ø³Ø± Ù‡Ù… (Ù‡Ù…Ø§Ù†Ø·ÙˆØ± Ú©Ù‡ Ø¯Ø± Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø§ØµÙ„ÛŒ Ø§Ù†ØªØ¸Ø§Ø± Ù…ÛŒâ€ŒØ±ÙˆØ¯).  
- Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒ Ø§ÛŒÙ† Ø±Ø§ Ø¨Ø¹Ø¯Ø§Ù‹ ØªÙˆØ³Ø¹Ù‡ Ø¨Ø¯ÛŒ: Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ HOG ÛŒØ§ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØªØµÙˆÛŒØ± Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒÙ….  
- Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒ Ø¯Ø± Ø³Ù…Øª Ú†Ù¾ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒ.
""")


